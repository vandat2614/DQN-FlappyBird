# DQN-FlappyBird

A reinforcement learning agent trained with **Deep Q-Network (DQN)** to play **Flappy Bird**, built using PyTorch and Gymnasium.

![Gameplay Demo](assets\demo.gif)
---

## ğŸŒ Environment

This project uses the external environment [`FlappyBird-v0`](https://github.com/markub3327/flappy-bird-gymnasium), a Gymnasium-compatible implementation of the classic Flappy Bird game.

This code is designed to work with the vector-based observation space, which is enabled by setting `use_lidar=False`.  If you're interested in the meaning of each feature, please refer to the original repository.


---

## ğŸ“‚ Project Structure

```
DQN-FlappyBird/
â”œâ”€â”€ config.yaml              # Contains settings for training, evaluation, and model architecture
â”œâ”€â”€ main.py                  # Entry point to load env, model, and run
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py             # Training logic for training the agent
â”‚   â”œâ”€â”€ test.py              # Demo: run a single episode with a trained agent
â”‚   â”œâ”€â”€ eval.py              # Generates statistics and evaluation metrics
â”‚   â”œâ”€â”€ neural_network.py
â”‚   â””â”€â”€ experience_replay.py # Experience replay buffer
â”œâ”€â”€ runs/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ weights/         # Checkpoints: best.pt, last.pt
    â”‚   â””â”€â”€ log              # Text log of training performance
    â””â”€â”€ eval/
        â””â”€â”€ results.json     #  Stores evaluation results:

```

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/vandat2614/DQN-FlappyBird.git
cd DQN-FlappyBird
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ‹ï¸â€â™‚ï¸ Training

```bash
python main.py --mode train
```

- Best model is saved at: `runs/train/weights/best.pt`
- Training parameters (e.g., learning rate, epsilon decay...) are specified under the `train` section of config
---

## ğŸ§ª Evaluate

```bash
python main.py --mode eval --config_path config.yaml --weights_path path/to/your/weights.pt
```

- Loads a trained `.pt` model to evaluate the agent's performance in the environment.
- Results are saved to `runs/eval/eval_log.json`
- Evaluation parameters (e.g., number of episodes) are specified under the `evaluate` section of config
- Itâ€™s recommended to set a `limit_score` in the `env` section of the config to prevent episodes from running indefinitely.
---

## ğŸ® Test


```bash
python main.py --mode test --config_path config.yaml --weights_path runs/train/weights/best.pt
```

- Runs a single episode with the trained agent and renders it in real-time.